{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:11:48.407640Z",
     "start_time": "2024-12-10T14:11:48.388440Z"
    }
   },
   "source": [
    "import import_ipynb\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:11:49.438445Z",
     "start_time": "2024-12-10T14:11:49.271161Z"
    }
   },
   "source": [
    "# préparation des données pour l'entrainement de 1992 - 2020\n",
    "data_pop = utils.generate_df_from_files(\"./data_cleaned/population\", \"_population\")\n",
    "data_fertility = utils.generate_df_from_files(\"./data_cleaned/fertility\", \"_fertility\")\n",
    "data_child = utils.generate_df_from_files(\"./data_cleaned/child_mortality\", \"_child_mortality\")\n",
    "data_capita = utils.generate_df_from_files(\"./data_cleaned/gdp_capita\", \"_gdp_capita\")\n",
    "data_climat = utils.generate_df_from_files(\"./\", \"climate_cleaned\")\n",
    "\n",
    "data_climat = np.array(data_climat)\n",
    "data_climat = pd.DataFrame(data_climat.squeeze())\n",
    "X_list = []\n",
    "\n",
    "for annee in range(11, 19):\n",
    "        \n",
    "    data_pop_slice = data_pop[annee].iloc[:, :]\n",
    "    data_fertility_slice = data_fertility[annee].iloc[:, 1:]\n",
    "    data_child_slice = data_child[annee].iloc[:, 1:]\n",
    "    data_capita_slice = data_capita[annee].iloc[:, 1:]\n",
    "    data_climat_slice = data_climat.iloc[:, 1:]\n",
    "    \n",
    "    concatenated_data = np.concatenate((\n",
    "        data_pop_slice, \n",
    "        data_fertility_slice, \n",
    "        data_child_slice, \n",
    "        data_capita_slice,\n",
    "        data_climat_slice\n",
    "    ), axis=1)\n",
    "\n",
    "    X_list.append(concatenated_data)\n",
    "\n",
    "X = np.vstack(X_list)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:11:50.418738Z",
     "start_time": "2024-12-10T14:11:50.409829Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:11:50.941104Z",
     "start_time": "2024-12-10T14:11:50.919567Z"
    }
   },
   "source": [
    "#preparation des labels pour classification 1992-->2020 labels à 3 classes\n",
    "import pandas as pd\n",
    "\n",
    "label_class_3 = pd.read_csv(\"labels_class_3_class.csv\")\n",
    "label_class_3.head()\n",
    "\n",
    "labels_list = []\n",
    "for i in range(len(label_class_3)):\n",
    "    label = label_class_3.iloc[i, :-1]\n",
    "    labels_list.append(label)\n",
    "\n",
    "y_class_3 = pd.concat(labels_list, axis=0, ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:12:26.225138Z",
     "start_time": "2024-12-10T14:12:26.219389Z"
    }
   },
   "cell_type": "code",
   "source": "y_class_3.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1144,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:12:33.172880Z",
     "start_time": "2024-12-10T14:12:33.156103Z"
    }
   },
   "source": [
    "#preparation des labels pour classification 1992-->2020 labels à 2 classes\n",
    "import pandas as pd\n",
    "\n",
    "label_class_2 = pd.read_csv(\"labels_class_2_class.csv\")\n",
    "label_class_2.head()\n",
    "\n",
    "labels_list = []\n",
    "for i in range(len(label_class_2)):\n",
    "    label = label_class_2.iloc[i, :-1]\n",
    "    labels_list.append(label)\n",
    "\n",
    "y_class_2 = pd.concat(labels_list, axis=0, ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "label_class_2.unique()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:12:35.180212Z",
     "start_time": "2024-12-10T14:12:35.155673Z"
    }
   },
   "source": [
    "# création des label pour tous les événements 1992->2020\n",
    "import pandas as pd\n",
    "df_delegations = pd.read_csv(\"./second_part_countries_cleaned_normalized.csv\")\n",
    "\n",
    "labels_list = []\n",
    "for i in range(len(df_delegations)):\n",
    "    label = df_delegations.iloc[i, :-1]\n",
    "    labels_list.append(label)\n",
    "\n",
    "y = pd.concat(labels_list, axis=0, ignore_index=True)\n"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:15:15.991320Z",
     "start_time": "2024-12-10T14:15:15.770671Z"
    }
   },
   "source": "",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m y_class\u001B[38;5;241m.\u001B[39munique()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'unique'"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:17:39.774962Z",
     "start_time": "2024-12-10T14:17:39.753470Z"
    }
   },
   "source": [
    "\n",
    "#récupération des pays\n",
    "country_names = X[:, 0]\n",
    "X = X[:, 1:]\n",
    "# convertion des données en float32\n",
    "X = np.array(X, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "y_class = np.array(y_class_3, dtype=np.float32) # choisir 2 ou 3 classes\n",
    "# séparation des données en train et test\n",
    "X_train, X_test, y_train, y_test, country_train, country_test, cl_train, cl_test = train_test_split(\n",
    "    X, y, country_names, y_class,  test_size=0.2, random_state=42)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:17:42.670858Z",
     "start_time": "2024-12-10T14:17:42.657778Z"
    }
   },
   "source": [
    "print(len(cl_train[ cl_train == 0]))\n",
    "print(len(cl_train[ cl_train == 1]))\n",
    "print(len(cl_train[ cl_train == 2]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795\n",
      "108\n",
      "12\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:10:36.392426Z",
     "start_time": "2024-12-10T14:10:36.385177Z"
    }
   },
   "source": [
    "#show keras version\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "# and tensorflow\n",
    "import tensorflow as tf \n",
    "\n",
    "print(tf.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.0\n",
      "2.18.0\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:10:36.415940Z",
     "start_time": "2024-12-10T14:10:36.412137Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:10:55.555917Z",
     "start_time": "2024-12-10T14:10:36.631857Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import MeanSquaredError as MSE, Accuracy\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "regression_loss_per_fold = []\n",
    "classification_loss_per_fold = []\n",
    "regression_mse_per_fold = []\n",
    "classification_accuracy_per_fold = []\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(cl_train), y=cl_train)\n",
    "class_weight_array = np.array(class_weights)\n",
    "\n",
    "\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    cl_train_fold, cl_val_fold = cl_train[train_index], cl_train[val_index]\n",
    "    \n",
    "    sample_weights = np.array([class_weight_array[int(label)] for label in cl_train_fold])\n",
    "\n",
    "    inputs = Input(shape=(X_train.shape[1],))\n",
    "    x1 = Dense(10, activation='relu')(inputs)\n",
    "    x2_reg = Dense(8, activation='relu')(x1)\n",
    "\n",
    "    output_reg = Dense(1, activation='relu', name='regression_output')(x2_reg)\n",
    "    output_clf = Dense(1, activation='sigmoid', name='classification_output')(x1)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[output_reg, output_clf])\n",
    "    model.compile(\n",
    "        optimizer=Adam(),\n",
    "        loss={'regression_output': MeanSquaredError(), 'classification_output': BinaryCrossentropy()},\n",
    "        metrics={'regression_output': 'mse', 'classification_output': Accuracy()}\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_fold, \n",
    "        {'regression_output': y_train_fold, 'classification_output': cl_train_fold}, \n",
    "        epochs=40,\n",
    "        batch_size=16, \n",
    "        validation_data=(X_val_fold, {'regression_output': y_val_fold, 'classification_output': cl_val_fold}),\n",
    "            sample_weight=sample_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    regression_loss_per_fold.append(history.history['regression_output_loss'])\n",
    "    classification_loss_per_fold.append(history.history['classification_output_loss'])\n",
    "    regression_mse_per_fold.append(history.history['regression_output_mse'])\n",
    "    classification_accuracy_per_fold.append(history.history['classification_output_accuracy'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for loss in regression_loss_per_fold:\n",
    "    plt.plot(loss, label='Fold Regression Loss')\n",
    "plt.title('Regression Loss for All Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for loss in classification_loss_per_fold:\n",
    "    plt.plot(loss, label='Fold Classification Loss')\n",
    "plt.title('Classification Loss for All Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for mse in regression_mse_per_fold:\n",
    "    plt.plot(mse, label='Fold Regression MSE')\n",
    "plt.title('Regression MSE (Mean Squared Error) for All Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for acc in classification_accuracy_per_fold:\n",
    "    plt.plot(acc, label='Fold Classification Accuracy')\n",
    "plt.title('Classification Accuracy for All Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "avg_val_loss = np.mean([np.min(loss) for loss in regression_loss_per_fold])\n",
    "avg_val_accuracy = np.mean([np.max(acc) for acc in classification_accuracy_per_fold])\n",
    "\n",
    "print(f'Average Validation Loss across {n_folds} folds: {avg_val_loss}')\n",
    "print(f'Average Validation Accuracy across {n_folds} folds: {avg_val_accuracy}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.1020 - loss: 0.7673 - regression_output_loss: 0.6654 - regression_output_mse: 0.1655 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.1162 - val_loss: 0.7033 - val_regression_output_loss: 0.5843 - val_regression_output_mse: 0.1522\n",
      "Epoch 2/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0841 - loss: 0.6686 - regression_output_loss: 0.5846 - regression_output_mse: 0.1496 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.1079 - val_loss: 0.6513 - val_regression_output_loss: 0.5416 - val_regression_output_mse: 0.1364\n",
      "Epoch 3/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.1045 - loss: 0.6490 - regression_output_loss: 0.5444 - regression_output_mse: 0.1362 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.1008 - val_loss: 0.5903 - val_regression_output_loss: 0.4885 - val_regression_output_mse: 0.1193\n",
      "Epoch 4/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0912 - loss: 0.6200 - regression_output_loss: 0.5288 - regression_output_mse: 0.1244 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0941 - val_loss: 0.5287 - val_regression_output_loss: 0.4351 - val_regression_output_mse: 0.1047\n",
      "Epoch 5/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0764 - loss: 0.5610 - regression_output_loss: 0.4845 - regression_output_mse: 0.0977 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0867 - val_loss: 0.5008 - val_regression_output_loss: 0.4153 - val_regression_output_mse: 0.1018\n",
      "Epoch 6/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0878 - loss: 0.5424 - regression_output_loss: 0.4546 - regression_output_mse: 0.1073 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0792 - val_loss: 0.4830 - val_regression_output_loss: 0.4053 - val_regression_output_mse: 0.0995\n",
      "Epoch 7/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0884 - loss: 0.5173 - regression_output_loss: 0.4288 - regression_output_mse: 0.1039 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0730 - val_loss: 0.5258 - val_regression_output_loss: 0.4515 - val_regression_output_mse: 0.0960\n",
      "Epoch 8/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0877 - loss: 0.5349 - regression_output_loss: 0.4472 - regression_output_mse: 0.1072 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0657 - val_loss: 0.4902 - val_regression_output_loss: 0.4237 - val_regression_output_mse: 0.0880\n",
      "Epoch 9/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0631 - loss: 0.4329 - regression_output_loss: 0.3699 - regression_output_mse: 0.0836 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0602 - val_loss: 0.4939 - val_regression_output_loss: 0.4331 - val_regression_output_mse: 0.0954\n",
      "Epoch 10/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0715 - loss: 0.4429 - regression_output_loss: 0.3713 - regression_output_mse: 0.1029 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0561 - val_loss: 0.4632 - val_regression_output_loss: 0.4068 - val_regression_output_mse: 0.0872\n",
      "Epoch 11/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0820 - loss: 0.4226 - regression_output_loss: 0.3406 - regression_output_mse: 0.0823 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0556 - val_loss: 0.5706 - val_regression_output_loss: 0.5130 - val_regression_output_mse: 0.1255\n",
      "Epoch 12/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0685 - loss: 0.4849 - regression_output_loss: 0.4164 - regression_output_mse: 0.1292 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0514 - val_loss: 0.4603 - val_regression_output_loss: 0.4084 - val_regression_output_mse: 0.0915\n",
      "Epoch 13/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0666 - loss: 0.3916 - regression_output_loss: 0.3250 - regression_output_mse: 0.0897 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0494 - val_loss: 0.4671 - val_regression_output_loss: 0.4168 - val_regression_output_mse: 0.0952\n",
      "Epoch 14/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0819 - loss: 0.4815 - regression_output_loss: 0.3996 - regression_output_mse: 0.1006 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0483 - val_loss: 0.4237 - val_regression_output_loss: 0.3748 - val_regression_output_mse: 0.0812\n",
      "Epoch 15/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0553 - loss: 0.4093 - regression_output_loss: 0.3540 - regression_output_mse: 0.0884 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0465 - val_loss: 0.4627 - val_regression_output_loss: 0.4150 - val_regression_output_mse: 0.0937\n",
      "Epoch 16/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 13ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0756 - loss: 0.3900 - regression_output_loss: 0.3145 - regression_output_mse: 0.0915 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0461 - val_loss: 0.5141 - val_regression_output_loss: 0.4637 - val_regression_output_mse: 0.0912\n",
      "Epoch 17/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0561 - loss: 0.3850 - regression_output_loss: 0.3289 - regression_output_mse: 0.0865 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0461 - val_loss: 0.5232 - val_regression_output_loss: 0.4727 - val_regression_output_mse: 0.0961\n",
      "Epoch 18/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0519 - loss: 0.3879 - regression_output_loss: 0.3360 - regression_output_mse: 0.0843 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0447 - val_loss: 0.5099 - val_regression_output_loss: 0.4608 - val_regression_output_mse: 0.0926\n",
      "Epoch 19/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0762 - loss: 0.3746 - regression_output_loss: 0.2984 - regression_output_mse: 0.0859 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0428 - val_loss: 0.5011 - val_regression_output_loss: 0.4541 - val_regression_output_mse: 0.0915\n",
      "Epoch 20/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0637 - loss: 0.4013 - regression_output_loss: 0.3375 - regression_output_mse: 0.1011 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0435 - val_loss: 0.5029 - val_regression_output_loss: 0.4547 - val_regression_output_mse: 0.0925\n",
      "Epoch 21/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0575 - loss: 0.4104 - regression_output_loss: 0.3528 - regression_output_mse: 0.1050 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0422 - val_loss: 0.4652 - val_regression_output_loss: 0.4185 - val_regression_output_mse: 0.0787\n",
      "Epoch 22/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0578 - loss: 0.3710 - regression_output_loss: 0.3133 - regression_output_mse: 0.0662 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0417 - val_loss: 0.4650 - val_regression_output_loss: 0.4184 - val_regression_output_mse: 0.0792\n",
      "Epoch 23/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0500 - loss: 0.3590 - regression_output_loss: 0.3090 - regression_output_mse: 0.0906 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0417 - val_loss: 0.4506 - val_regression_output_loss: 0.4042 - val_regression_output_mse: 0.0734\n",
      "Epoch 24/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0535 - loss: 0.3296 - regression_output_loss: 0.2762 - regression_output_mse: 0.0700 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0426 - val_loss: 0.6047 - val_regression_output_loss: 0.5536 - val_regression_output_mse: 0.1107\n",
      "Epoch 25/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0464 - loss: 0.3646 - regression_output_loss: 0.3182 - regression_output_mse: 0.0902 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0408 - val_loss: 0.5647 - val_regression_output_loss: 0.5155 - val_regression_output_mse: 0.0974\n",
      "Epoch 26/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 16ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0522 - loss: 0.3129 - regression_output_loss: 0.2607 - regression_output_mse: 0.0890 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0412 - val_loss: 0.6021 - val_regression_output_loss: 0.5519 - val_regression_output_mse: 0.1138\n",
      "Epoch 27/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0624 - loss: 0.3572 - regression_output_loss: 0.2947 - regression_output_mse: 0.0878 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0405 - val_loss: 0.5850 - val_regression_output_loss: 0.5354 - val_regression_output_mse: 0.1090\n",
      "Epoch 28/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0512 - loss: 0.2900 - regression_output_loss: 0.2388 - regression_output_mse: 0.0807 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0410 - val_loss: 0.5946 - val_regression_output_loss: 0.5441 - val_regression_output_mse: 0.1118\n",
      "Epoch 29/40\n",
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0496 - loss: 0.3278 - regression_output_loss: 0.2781 - regression_output_mse: 0.0837 - val_classification_output_accuracy: 0.0000e+00 - val_classification_output_loss: 0.0391 - val_loss: 0.5432 - val_regression_output_loss: 0.4950 - val_regression_output_mse: 0.0944\n",
      "Epoch 30/40\n",
      "\u001B[1m 4/46\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - classification_output_accuracy: 0.0000e+00 - classification_output_loss: 0.0454 - loss: 0.3066 - regression_output_loss: 0.2612 - regression_output_mse: 0.06966"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 46\u001B[0m\n\u001B[0;32m     39\u001B[0m model \u001B[38;5;241m=\u001B[39m Model(inputs\u001B[38;5;241m=\u001B[39minputs, outputs\u001B[38;5;241m=\u001B[39m[output_reg, output_clf])\n\u001B[0;32m     40\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[0;32m     41\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39mAdam(),\n\u001B[0;32m     42\u001B[0m     loss\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mregression_output\u001B[39m\u001B[38;5;124m'\u001B[39m: MeanSquaredError(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassification_output\u001B[39m\u001B[38;5;124m'\u001B[39m: BinaryCrossentropy()},\n\u001B[0;32m     43\u001B[0m     metrics\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mregression_output\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmse\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassification_output\u001B[39m\u001B[38;5;124m'\u001B[39m: Accuracy()}\n\u001B[0;32m     44\u001B[0m )\n\u001B[1;32m---> 46\u001B[0m history \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfit(\n\u001B[0;32m     47\u001B[0m     X_train_fold, \n\u001B[0;32m     48\u001B[0m     {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mregression_output\u001B[39m\u001B[38;5;124m'\u001B[39m: y_train_fold, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassification_output\u001B[39m\u001B[38;5;124m'\u001B[39m: cl_train_fold}, \n\u001B[0;32m     49\u001B[0m     epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m,\n\u001B[0;32m     50\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, \n\u001B[0;32m     51\u001B[0m     validation_data\u001B[38;5;241m=\u001B[39m(X_val_fold, {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mregression_output\u001B[39m\u001B[38;5;124m'\u001B[39m: y_val_fold, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassification_output\u001B[39m\u001B[38;5;124m'\u001B[39m: cl_val_fold}),\n\u001B[0;32m     52\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39msample_weights,\n\u001B[0;32m     53\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     54\u001B[0m )\n\u001B[0;32m     56\u001B[0m regression_loss_per_fold\u001B[38;5;241m.\u001B[39mappend(history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mregression_output_loss\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     57\u001B[0m classification_loss_per_fold\u001B[38;5;241m.\u001B[39mappend(history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassification_output_loss\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PCD\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PCD\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[0;32m    319\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m--> 320\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_function(iterator)\n\u001B[0;32m    321\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(step, logs)\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PCD\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PCD\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PCD\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m tracing_compilation\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[0;32m    879\u001B[0m     args, kwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config\n\u001B[0;32m    880\u001B[0m )\n\u001B[0;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[0;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PCD\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m function\u001B[38;5;241m.\u001B[39m_call_flat(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    140\u001B[0m     flat_inputs, captured_inputs\u001B[38;5;241m=\u001B[39mfunction\u001B[38;5;241m.\u001B[39mcaptured_inputs\n\u001B[0;32m    141\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PCD\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inference_function\u001B[38;5;241m.\u001B[39mcall_preflattened(args)\n\u001B[0;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1324\u001B[0m     args,\n\u001B[0;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1326\u001B[0m     executing_eagerly)\n\u001B[0;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PCD\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcall_flat(\u001B[38;5;241m*\u001B[39margs)\n\u001B[0;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PCD\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[0;32m    252\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname,\n\u001B[0;32m    253\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    254\u001B[0m         \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mflat_outputs),\n\u001B[0;32m    255\u001B[0m     )\n\u001B[0;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    261\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PCD\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1681\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1682\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1683\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute(\n\u001B[0;32m   1684\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1685\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   1686\u001B[0m       inputs\u001B[38;5;241m=\u001B[39mtensor_inputs,\n\u001B[0;32m   1687\u001B[0m       attrs\u001B[38;5;241m=\u001B[39mattrs,\n\u001B[0;32m   1688\u001B[0m       ctx\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1689\u001B[0m   )\n\u001B[0;32m   1690\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1691\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1692\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1693\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1697\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1698\u001B[0m   )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PCD\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     54\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import MeanSquaredError as MSE, Accuracy\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "regression_loss_per_fold = []\n",
    "classification_loss_per_fold = []\n",
    "regression_mse_per_fold = []\n",
    "classification_accuracy_per_fold = []\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(cl_train), y=cl_train)\n",
    "class_weight_array = np.array(class_weights)\n",
    "\n",
    "\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    cl_train_fold, cl_val_fold = cl_train[train_index], cl_train[val_index]\n",
    "\n",
    "    sample_weights = np.array([class_weight_array[label] for label in cl_train_fold])\n",
    "\n",
    "    inputs = Input(shape=(X_train.shape[1],))\n",
    "    x1 = Dense(10, activation='relu')(inputs)\n",
    "    x2_reg = Dense(8, activation='relu')(x1)\n",
    "\n",
    "    output_reg = Dense(1, activation='relu', name='regression_output')(x2_reg)\n",
    "    output_clf = Dense(1, activation='sigmoid', name='classification_output')(x1)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[output_reg, output_clf])\n",
    "    model.compile(\n",
    "        optimizer=Adam(),\n",
    "        loss={'regression_output': MeanSquaredError(), 'classification_output': BinaryCrossentropy()},\n",
    "        metrics={'regression_output': 'mse', 'classification_output': Accuracy()}\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_fold, \n",
    "        {'regression_output': y_train_fold, 'classification_output': cl_train_fold}, \n",
    "        epochs=40,\n",
    "        batch_size=16, \n",
    "        validation_data=(X_val_fold, {'regression_output': y_val_fold, 'classification_output': cl_val_fold}),\n",
    "            sample_weight=sample_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    regression_loss_per_fold.append(history.history['regression_output_loss'])\n",
    "    classification_loss_per_fold.append(history.history['classification_output_loss'])\n",
    "    regression_mse_per_fold.append(history.history['regression_output_mse'])\n",
    "    classification_accuracy_per_fold.append(history.history['classification_output_accuracy'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for loss in regression_loss_per_fold:\n",
    "    plt.plot(loss, label='Fold Regression Loss')\n",
    "plt.title('Regression Loss for All Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for loss in classification_loss_per_fold:\n",
    "    plt.plot(loss, label='Fold Classification Loss')\n",
    "plt.title('Classification Loss for All Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for mse in regression_mse_per_fold:\n",
    "    plt.plot(mse, label='Fold Regression MSE')\n",
    "plt.title('Regression MSE (Mean Squared Error) for All Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for acc in classification_accuracy_per_fold:\n",
    "    plt.plot(acc, label='Fold Classification Accuracy')\n",
    "plt.title('Classification Accuracy for All Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "avg_val_loss = np.mean([np.min(loss) for loss in regression_loss_per_fold])\n",
    "avg_val_accuracy = np.mean([np.max(acc) for acc in classification_accuracy_per_fold])\n",
    "\n",
    "print(f'Average Validation Loss across {n_folds} folds: {avg_val_loss}')\n",
    "print(f'Average Validation Accuracy across {n_folds} folds: {avg_val_accuracy}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Code à 2 classes\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError, CategoricalCrossentropy\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "n_folds = 3\n",
    "N_EP = 40\n",
    "\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "regression_loss_per_fold = []\n",
    "classification_loss_per_fold = []\n",
    "regression_mse_per_fold = []\n",
    "classification_accuracy_per_fold = []\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(cl_train), y=cl_train)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "def weighted_loss(y_true, y_pred):\n",
    "    print(\"y_true shape:\", y_true.shape)\n",
    "    print(\"y_pred shape:\", y_pred.shape)\n",
    "    \n",
    "    cce_loss = CategoricalCrossentropy()(y_true, y_pred)\n",
    "    \n",
    "    return cce_loss\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    cl_train_fold, cl_val_fold = cl_train[train_index], cl_train[val_index]\n",
    "\n",
    "    cl_train_fold_onehot = to_categorical(cl_train_fold, num_classes=3)\n",
    "    cl_val_fold_onehot = to_categorical(cl_val_fold, num_classes=3)\n",
    "\n",
    "    inputs = Input(shape=(X_train.shape[1],))\n",
    "    first_l = Dense(16, activation='relu')(inputs) \n",
    "    second_l = Dense(8, activation='relu')(first_l)\n",
    "\n",
    "    regression_output = Dense(1, activation='linear', name='regression_output')(second_l)\n",
    "    classification_output = Dense(3, activation='softmax', name='classification_output')(second_l)\n",
    "    model = Model(inputs=inputs, outputs=[regression_output, classification_output])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(),\n",
    "        loss={\n",
    "            'regression_output': 'mse',\n",
    "            'classification_output': 'categorical_crossentropy'\n",
    "        },\n",
    "        metrics={\n",
    "            'regression_output': ['mse'],\n",
    "            'classification_output': ['accuracy']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Generate sample weights\n",
    "    regression_sample_weight = generate_sample_weights(y_train_fold)\n",
    "    classification_sample_weight = generate_sample_weights(cl_train_fold)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_fold,\n",
    "        {\n",
    "            'regression_output': y_train_fold.reshape(-1, 1),\n",
    "            'classification_output': cl_train_fold_onehot\n",
    "        },\n",
    "        sample_weight={\n",
    "            'regression_output': regression_sample_weight,\n",
    "            'classification_output': classification_sample_weight\n",
    "        },\n",
    "        epochs=N_EP,\n",
    "        batch_size=16,\n",
    "        validation_data=(\n",
    "            X_val_fold,\n",
    "            {\n",
    "                'regression_output': y_val_fold.reshape(-1, 1),\n",
    "                'classification_output': cl_val_fold_onehot\n",
    "            }\n",
    "        ),\n",
    "        verbose=1)\n",
    "\n",
    "    regression_loss_per_fold.append(history.history['regression_output_loss'])\n",
    "    classification_loss_per_fold.append(history.history['classification_output_loss'])\n",
    "    regression_mse_per_fold.append(history.history['regression_output_mse'])\n",
    "    classification_accuracy_per_fold.append(history.history['classification_output_accuracy'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for loss in regression_loss_per_fold:\n",
    "    plt.plot(loss, label='Fold Regression Loss')\n",
    "plt.title('Regression Loss for All Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for loss in classification_loss_per_fold:\n",
    "    plt.plot(loss, label='Fold Classification Loss')\n",
    "plt.title('Classification Loss for All Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ** Regression Accuracy (or MSE) **\n",
    "plt.figure(figsize=(12, 6))\n",
    "for mse in regression_mse_per_fold:\n",
    "    plt.plot(mse, label='Fold Regression MSE')\n",
    "plt.title('Regression MSE for All Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ** Classification Accuracy **\n",
    "plt.figure(figsize=(12, 6))\n",
    "for acc in classification_accuracy_per_fold:\n",
    "    plt.plot(acc, label='Fold Classification Accuracy')\n",
    "plt.title('Classification Accuracy for All Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "avg_regression_loss = np.mean([np.min(loss) for loss in regression_loss_per_fold])\n",
    "avg_classification_loss = np.mean([np.min(loss) for loss in classification_loss_per_fold])\n",
    "avg_regression_mse = np.mean([np.min(mse) for mse in regression_mse_per_fold])\n",
    "avg_classification_accuracy = np.mean([np.max(acc) for acc in classification_accuracy_per_fold])\n",
    "\n",
    "print(f'Average Regression Loss: {avg_regression_loss}')\n",
    "print(f'Average Classification Loss: {avg_classification_loss}')\n",
    "print(f'Average Regression MSE: {avg_regression_mse}')\n",
    "print(f'Average Classification Accuracy: {avg_classification_accuracy}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Code à 3 classes",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Lists to store F1 and accuracy scores for each fold\n",
    "f1_scores_per_fold = []\n",
    "accuracy_scores_per_fold = []\n",
    "\n",
    "# Loop through each fold to evaluate metrics\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    cl_train_fold, cl_val_fold = cl_train[train_index], cl_train[val_index]\n",
    "\n",
    "    # Make predictions for the classification model on the validation set\n",
    "    y_pred_class = classification_model.predict(X_val_fold)\n",
    "    y_pred_class = np.argmax(y_pred_class, axis=1)  # Convert probabilities to class labels (argmax for multi-class)\n",
    "\n",
    "    # Calculate F1 score and accuracy for the current fold\n",
    "    f1 = f1_score(cl_val_fold, y_pred_class, average='weighted')  # Weighted F1 for multi-class\n",
    "    accuracy = accuracy_score(cl_val_fold, y_pred_class)\n",
    "\n",
    "    # Append scores to the lists\n",
    "    f1_scores_per_fold.append(f1)\n",
    "    accuracy_scores_per_fold.append(accuracy)\n",
    "\n",
    "# Calculate the mean F1 score and accuracy score across all folds\n",
    "mean_f1_score = np.mean(f1_scores_per_fold)\n",
    "mean_accuracy_score = np.mean(accuracy_scores_per_fold)\n",
    "\n",
    "# Print the mean scores\n",
    "print(f'Mean F1 Score across all folds: {mean_f1_score:.4f}')\n",
    "print(f'Mean Accuracy Score across all folds: {mean_accuracy_score:.4f}')\n",
    "\n",
    "# Compute confusion matrix for the final fold or average over all folds\n",
    "# Using the last fold for demonstration purposes\n",
    "y_pred_class = classification_model.predict(X_val_fold)\n",
    "y_pred_class = np.argmax(y_pred_class, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(cl_val_fold, y_pred_class)\n",
    "\n",
    "# Plot the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])\n",
    "plt.title('Confusion Matrix for 3-Class Classification Task')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "# version simple du NN en format NON séquentiel\n",
    "\"\"\"\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(50, activation='relu')(inputs)\n",
    "#x = Dropout(0.3)(x)\n",
    "\n",
    "#x = Dense(16, activation='relu')(x)\n",
    "#x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(12, activation='relu')(x)\n",
    "\n",
    "outputs = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=80, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PCD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
