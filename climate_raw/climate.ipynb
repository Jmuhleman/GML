{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cd3023-2e9e-40aa-9b50-18761ddda9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from shapely.geometry import Point\n",
    "import random\n",
    "import ast\n",
    "\n",
    "# prendre une cartede plus haute resolution pour plus de pays\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres')) \n",
    "climate_raster = 'map.tif'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a92be9-f406-46df-b05c-399286c416ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a42145-b350-454a-bb45-c80d32360ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Path to your shapefile\n",
    "shapefile_path = 'map/c1976_2000.shp'\n",
    "\n",
    "# Load the shapefile using GeoPandas\n",
    "climate_shapefile = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Step 1: Display the column names to understand what data is available\n",
    "print(\"Column Names in the Shapefile:\")\n",
    "print(climate_shapefile.columns)\n",
    "\n",
    "# Step 2: Check the first few rows to inspect the structure of the data\n",
    "print(\"\\nFirst few rows of the Shapefile:\")\n",
    "print(climate_shapefile.head())\n",
    "\n",
    "# Step 3: Check the data types of each column\n",
    "print(\"\\nData types of each column:\")\n",
    "print(climate_shapefile.dtypes)\n",
    "\n",
    "# Step 4: (Optional) Describe the numeric columns, if any, to get an overview of the data\n",
    "print(\"\\nSummary of numeric columns:\")\n",
    "print(climate_shapefile.describe())\n",
    "\n",
    "# Step 5: (Optional) If you expect a geometry column, check the geometry of the shapefile\n",
    "print(\"\\nGeometry column (geometries present in the shapefile):\")\n",
    "print(climate_shapefile.geometry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f85ed5a6-d04e-46dd-989a-d6389f020bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Path to your shapefile\n",
    "shapefile_path = 'map/c1976_2000.shp'\n",
    "\n",
    "# Load the shapefile using GeoPandas\n",
    "climate_shapefile = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(climate_shapefile.head())\n",
    "\n",
    "# Since there's no 'country' column, you need to intersect the geometries with a world borders dataset\n",
    "# You can use a world borders dataset provided by GeoPandas, like \"naturalearth_lowres\"\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# Ensure both datasets use the same coordinate reference system (CRS)\n",
    "# Reproject the world data to match the shapefile CRS if needed\n",
    "if climate_shapefile.crs != world.crs:\n",
    "    world = world.to_crs(climate_shapefile.crs)\n",
    "\n",
    "# Perform a spatial join to map climate polygons to countries\n",
    "# This will give each climate polygon a corresponding country based on spatial intersection\n",
    "climate_with_countries = gpd.sjoin(climate_shapefile, world, how=\"inner\", op=\"intersects\")\n",
    "\n",
    "# Now group the data by country and get the unique climate classifications (GRIDCODEs) for each country\n",
    "climate_per_country = climate_with_countries.groupby('name')['GRIDCODE'].unique()\n",
    "\n",
    "# Convert to a dictionary for easier access\n",
    "climate_per_country_dict = climate_per_country.to_dict()\n",
    "\n",
    "# Display the climate types for each country\n",
    "for country, climates in climate_per_country_dict.items():\n",
    "    print(f\"Country: {country}, Climate Types: {climates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f99be0fb-1cee-43d7-b1f3-f965cdd289a9",
   "metadata": {},
   "outputs": [],
   "source": [
    " df =pd.DataFrame([climate_per_country_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d43f6436-06b8-4da8-995c-195595b90bc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.transpose().to_csv('climate_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb856a-b2f6-4faf-bcb2-c164504067d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b8c5d9e-1aaf-460b-a752-18812aa010fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('climate_names.csv')\n",
    "df.rename(columns={'Unnamed: 0': 'country'}, inplace=True)\n",
    "df.rename(columns={'0': 'climate'}, inplace=True)\n",
    "\n",
    "\n",
    "def climate_to_continuous(koppen_code):\n",
    "    temperature_map = {\n",
    "        11: 1.0,  # Af\n",
    "        12: 0.9,  # Am\n",
    "        13: 0.8,  # As\n",
    "        14: 0.7,  # Aw\n",
    "        21: 0.5,  # BWk\n",
    "        22: 0.6,  # BWh\n",
    "        26: 0.3,  # BSk\n",
    "        27: 0.4,  # BSh\n",
    "        31: 0.6,  # Cfa\n",
    "        32: 0.5,  # Cfb\n",
    "        33: 0.4,  # Cfc\n",
    "        34: 0.7,  # Csa\n",
    "        35: 0.5,  # Csb\n",
    "        36: 0.4,  # Csc\n",
    "        37: 0.5,  # Cwa\n",
    "        38: 0.4,  # Cwb\n",
    "        39: 0.3,  # Cwc\n",
    "        41: 0.6,  # Dfa\n",
    "        42: 0.5,  # Dfb\n",
    "        43: 0.4,  # Dfc\n",
    "        44: 0.3,  # Dfd\n",
    "        45: 0.4,  # Dsa\n",
    "        46: 0.4,  # Dsb\n",
    "        47: 0.4,  # Dsc\n",
    "        48: 0.4,  # Dsd\n",
    "        49: 0.3,  # Dwa\n",
    "        50: 0.2,  # Dwb\n",
    "        51: 0.1,  # Dwc\n",
    "        52: 0.1,  # Dwd\n",
    "        61: 0.1,  # EF\n",
    "        62: 0.1   # ET\n",
    "    }\n",
    "    \n",
    "    precipitation_map = {\n",
    "        11: 1.0,  # Af\n",
    "        12: 0.9,  # Am\n",
    "        13: 0.9,  # As\n",
    "        14: 0.7,  # Aw\n",
    "        21: 0.1,  # BWk\n",
    "        22: 0.2,  # BWh\n",
    "        26: 0.3,  # BSk\n",
    "        27: 0.4,  # BSh\n",
    "        31: 0.7,  # Cfa\n",
    "        32: 0.6,  # Cfb\n",
    "        33: 0.5,  # Cfc\n",
    "        34: 0.8,  # Csa\n",
    "        35: 0.6,  # Csb\n",
    "        36: 0.5,  # Csc\n",
    "        37: 0.7,  # Cwa\n",
    "        38: 0.8,  # Cwb\n",
    "        39: 0.6,  # Cwc\n",
    "        41: 0.5,  # Dfa\n",
    "        42: 0.4,  # Dfb\n",
    "        43: 0.3,  # Dfc\n",
    "        44: 0.2,  # Dfd\n",
    "        45: 0.4,  # Dsa\n",
    "        46: 0.4,  # Dsb\n",
    "        47: 0.4,  # Dsc\n",
    "        48: 0.4,  # Dsd\n",
    "        49: 0.3,  # Dwa\n",
    "        50: 0.2,  # Dwb\n",
    "        51: 0.1,  # Dwc\n",
    "        52: 0.1,  # Dwd\n",
    "        61: 0.1,  # EF\n",
    "        62: 0.1   # ET\n",
    "    }\n",
    "    \n",
    "    seasonality_map = {\n",
    "        11: 1.0,  # Af\n",
    "        12: 0.8,  # Am\n",
    "        13: 0.7,  # As\n",
    "        14: 0.6,  # Aw\n",
    "        21: 0.1,  # BWk\n",
    "        22: 0.1,  # BWh\n",
    "        26: 0.2,  # BSk\n",
    "        27: 0.3,  # BSh\n",
    "        31: 0.6,  # Cfa\n",
    "        32: 0.5,  # Cfb\n",
    "        33: 0.4,  # Cfc\n",
    "        34: 0.5,  # Csa\n",
    "        35: 0.5,  # Csb\n",
    "        36: 0.4,  # Csc\n",
    "        37: 0.5,  # Cwa\n",
    "        38: 0.4,  # Cwb\n",
    "        39: 0.3,  # Cwc\n",
    "        41: 0.5,  # Dfa\n",
    "        42: 0.4,  # Dfb\n",
    "        43: 0.3,  # Dfc\n",
    "        44: 0.3,  # Dfd\n",
    "        45: 0.4,  # Dsa\n",
    "        46: 0.4,  # Dsb\n",
    "        47: 0.4,  # Dsc\n",
    "        48: 0.4,  # Dsd\n",
    "        49: 0.3,  # Dwa\n",
    "        50: 0.2,  # Dwb\n",
    "        51: 0.1,  # Dwc\n",
    "        52: 0.1,  # Dwd\n",
    "        61: 0.1,  # EF\n",
    "        62: 0.1   # ET\n",
    "    }\n",
    "    \n",
    "    aridity_map = {\n",
    "        11: 0.1,  # Af\n",
    "        12: 0.2,  # Am\n",
    "        13: 0.2,  # As\n",
    "        14: 0.3,  # Aw\n",
    "        21: 0.9,  # BWk\n",
    "        22: 0.8,  # BWh\n",
    "        26: 0.6,  # BSk\n",
    "        27: 0.5,  # BSh\n",
    "        31: 0.5,  # Cfa\n",
    "        32: 0.5,  # Cfb\n",
    "        33: 0.4,  # Cfc\n",
    "        34: 0.4,  # Csa\n",
    "        35: 0.5,  # Csb\n",
    "        36: 0.4,  # Csc\n",
    "        37: 0.3,  # Cwa\n",
    "        38: 0.2,  # Cwb\n",
    "        39: 0.2,  # Cwc\n",
    "        41: 0.3,  # Dfa\n",
    "        42: 0.4,  # Dfb\n",
    "        43: 0.4,  # Dfc\n",
    "        44: 0.3,  # Dfd\n",
    "        45: 0.4,  # Dsa\n",
    "        46: 0.4,  # Dsb\n",
    "        47: 0.4,  # Dsc\n",
    "        48: 0.4,  # Dsd\n",
    "        49: 0.3,  # Dwa\n",
    "        50: 0.3,  # Dwb\n",
    "        51: 0.1,  # Dwc\n",
    "        52: 0.1,  # Dwd\n",
    "        61: 0.1,  # EF\n",
    "        62: 0.1   # ET\n",
    "    }\n",
    "    \n",
    "    # Convert the code into continuous values using the mappings above\n",
    "    T = temperature_map.get(koppen_code, np.nan)\n",
    "    P = precipitation_map.get(koppen_code, np.nan)\n",
    "    S = seasonality_map.get(koppen_code, np.nan)\n",
    "    A = aridity_map.get(koppen_code, np.nan)\n",
    "    \n",
    "    return {\n",
    "        'Temperature': T,\n",
    "        'Precipitation': P,\n",
    "        'Seasonality': S,\n",
    "        'Aridity': A\n",
    "    }\n",
    "\n",
    "def calculate_average_continuous(climate_codes):\n",
    "    temperature_list = []\n",
    "    precipitation_list = []\n",
    "    seasonality_list = []\n",
    "    aridity_list = []\n",
    "    \n",
    "    for code in climate_codes:\n",
    "        continuous_values = climate_to_continuous(code)\n",
    "        \n",
    "        if not np.isnan(continuous_values['Temperature']):\n",
    "            temperature_list.append(continuous_values['Temperature'])\n",
    "        if not np.isnan(continuous_values['Precipitation']):\n",
    "            precipitation_list.append(continuous_values['Precipitation'])\n",
    "        if not np.isnan(continuous_values['Seasonality']):\n",
    "            seasonality_list.append(continuous_values['Seasonality'])\n",
    "        if not np.isnan(continuous_values['Aridity']):\n",
    "            aridity_list.append(continuous_values['Aridity'])\n",
    "    \n",
    "    avg_temperature = np.nan if not temperature_list else sum(temperature_list) / len(temperature_list)\n",
    "    avg_precipitation = np.nan if not precipitation_list else sum(precipitation_list) / len(precipitation_list)\n",
    "    avg_seasonality = np.nan if not seasonality_list else sum(seasonality_list) / len(seasonality_list)\n",
    "    avg_aridity = np.nan if not aridity_list else sum(aridity_list) / len(aridity_list)\n",
    "    \n",
    "    return {\n",
    "        'Avg_Temperature': avg_temperature,\n",
    "        'Avg_Precipitation': avg_precipitation,\n",
    "        'Avg_Seasonality': avg_seasonality,\n",
    "        'Avg_Aridity': avg_aridity\n",
    "    }\n",
    "\n",
    "df['climate'] = df['climate'].apply(lambda x: list(map(int, ast.literal_eval(x.replace(' ', ',')))))\n",
    "df['Continuous_Climate'] = df['climate'].apply(calculate_average_continuous)\n",
    "\n",
    "df_expanded = pd.concat([df['country'], df['Continuous_Climate'].apply(pd.Series)], axis=1)\n",
    "\n",
    "df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9319742a-ed90-471e-84df-75ac1f88d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded.to_csv('climate_in_continuous.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a9f39db-5de3-49b0-86f0-9e3cfd25cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from shapely.geometry import Point\n",
    "import random\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "de = pd.read_csv('climate_in_continuous.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e71a56f-a50f-49da-b216-bb68eb6649ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f944a46d-3e9b-4abe-82f8-62c2bb1547d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = de.iloc[:, 2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d67c4877-620f-4086-8375-d3808d33e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Assuming dd is your DataFrame\n",
    "# Fit KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=0, n_init=\"auto\")\n",
    "kmeans.fit(dd)\n",
    "\n",
    "# Add labels to DataFrame\n",
    "dd['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Set up the figure for 2 subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot 1: Average Temperature vs. Average Aridity\n",
    "sns.scatterplot(ax=axes[0], data=dd, x='Avg_Temperature', y='Avg_Aridity', \n",
    "                hue='Cluster', palette='viridis', s=100)\n",
    "axes[0].set_title('Average Temperature vs. Average Aridity')\n",
    "axes[0].set_xlabel('Average Temperature')\n",
    "axes[0].set_ylabel('Average Aridity')\n",
    "\n",
    "# Plot 2: Average Precipitation vs. Average Seasonality\n",
    "sns.scatterplot(ax=axes[1], data=dd, x='Avg_Precipitation', y='Avg_Seasonality', \n",
    "                hue='Cluster', palette='viridis', s=100)\n",
    "axes[1].set_title('Average Precipitation vs. Average Seasonality')\n",
    "axes[1].set_xlabel('Average Precipitation')\n",
    "axes[1].set_ylabel('Average Seasonality')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18966624-bc6f-4fac-9d13-2917441b8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c4206ff-0ea7-4832-9012-3d2eb698f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['country'] = de['country']\n",
    "dd[(dd['Cluster'] == 1) & (dd['Avg_Temperature'] < 0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f628b9-c6ca-4bd3-8848-7b49aece548a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "549e0097-1717-4e23-886c-d9fcb487934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[dd['Avg_Temperature'] > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e5e6c7-3fb2-4a42-8022-dfe06c00d55c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PCD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
